{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    img_folders = []\n",
    "    folders = os.listdir(path)\n",
    "    for folder in folders:\n",
    "        img_folders.append(folder)\n",
    "        \n",
    "        label = folder.split(\"_\")[0]\n",
    "        labels.append(label)\n",
    "        \n",
    "    img_folders = np.array(img_folders)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    training_folders, testing_folders, y_train, y_test = train_test_split(img_folders, labels, test_size=0.3, random_state=0, stratify=labels)\n",
    "    print(training_folders.shape,testing_folders.shape)\n",
    "    \n",
    "    np.save(\"training_folders\",training_folders)\n",
    "    np.save(\"testing_folders\",testing_folders)\n",
    "    np.save(\"training_labels\",y_train)\n",
    "    np.save(\"testing_labels\",y_test)\n",
    "    \n",
    "    return training_folders, testing_folders, y_train, y_test\n",
    "\n",
    "def find_features(path,training_folders):\n",
    "    sift = cv.xfeatures2d.SIFT_create()\n",
    "    descriptor_list = []\n",
    "    for folder in training_folders:\n",
    "        file_path = path + folder\n",
    "        images = os.listdir(file_path)\n",
    "        video_descriptors_list = []\n",
    "        for img in images : \n",
    "            img_path = file_path + \"/\" + img\n",
    "            image = cv.imread(img_path,0)\n",
    "            kp,des = sift.detectAndCompute(image, None)\n",
    "            video_descriptors_list.append(des)\n",
    "        descriptor_list.append(video_descriptors_list)\n",
    "    \n",
    "    descriptor_list = np.array(descriptor_list)\n",
    "    print(type(descriptor_list[0]),type(descriptor_list[0][0]))\n",
    "    \n",
    "    np.save(\"./Data/training_descriptors\",descriptor_list)\n",
    "    print(descriptor_list.shape)\n",
    "\n",
    "def cluster(descriptor_stack):\n",
    "    kmeans_obj = KMeans(n_clusters = 2)\n",
    "    clustered_objects = kmeans_obj.fit_predict(descriptor_stack)\n",
    "    clustered_objects = np.array(clustered_objects)\n",
    "    np.save(\"clustered_objects\",clustered_objects)\n",
    "    return clustered_objects,kmeans_obj\n",
    "    \n",
    "def stack_vertically(descriptor_list):\n",
    "    descriptor_stack = []\n",
    "    for i in range(descriptor_list.shape[0]):\n",
    "#         print(descriptor_list[i].shape)\n",
    "        for j in range(descriptor_list[i].shape[0]):\n",
    "#             print(descriptor_list[i][j].shape)\n",
    "#             print(i,j)\n",
    "            if descriptor_list[i][j] is not None:\n",
    "                descriptor_stack.extend(descriptor_list[i][j])\n",
    "    \n",
    "    descriptor_stack = np.array(descriptor_stack)\n",
    "    np.save(\"./Data/descriptor_stack\",descriptor_stack)\n",
    "    return np.array(descriptor_stack)\n",
    "\n",
    "def create_bovw_histogram(clustered_objects,training_folders,descriptor_list,path):\n",
    "    \n",
    "    histogram = np.array([np.zeros(2) for i in range(training_folders.shape[0])])\n",
    "    \n",
    "    for i in range(descriptor_list.shape[0]):\n",
    "        for j in range(descriptor_list[i].shape[0]):\n",
    "            if descriptor_list[i, j] is not None:\n",
    "                for k in range(descriptor_list[i][j].shape[0]):\n",
    "                    index = clustered_objects[i + j + k]\n",
    "\n",
    "                    histogram[i][index] += 1\n",
    "    \n",
    "    np.save(\"./Data/histogram\",histogram)\n",
    "    return histogram\n",
    "\n",
    "def normalize_histogram(histogram):\n",
    "    scale = StandardScaler().fit(histogram)\n",
    "    standardized_histogram = scale.transform(histogram)\n",
    "    \n",
    "    standardized_histogram = np.array(standardized_histogram)\n",
    "    \n",
    "    np.save(\"standardized_histogram\",standardized_histogram)\n",
    "    return standardized_histogram,scale\n",
    "\n",
    "def train_bovw(histogram,training_labels,clf):\n",
    "    clf.fit(histogram, training_labels)\n",
    "    return clf\n",
    "\n",
    "\n",
    "    \n",
    "def recognize_test_videos(testing_label,testing_folder,path,clf,scale,kmeans_obj):\n",
    "    test_histogram = [np.zeros(20) for i in range(testing_folder.shape[0])]\n",
    "    sift = cv.xfeatures2d.SIFT_create()\n",
    "\n",
    "    predicted_labels = []\n",
    "    \n",
    "    for i in range(testing_folder.shape[0]):\n",
    "        folder = testing_folder[i]\n",
    "        file_path = path + folder\n",
    "        images = os.listdir(file_path)\n",
    "        \n",
    "#         test_histogram = [0 for j in range(20)]\n",
    "        for img in images : \n",
    "            img_path = file_path + \"/\" + img\n",
    "            image = cv.imread(img_path,0)\n",
    "            kp,des = sift.detectAndCompute(image, None)\n",
    "            if des is not None:\n",
    "                for d in des:\n",
    "                    d = np.reshape(d, (1, d.shape[0]))\n",
    "                    test_clusters = kmeans_obj.predict(d)\n",
    "                    test_histogram[i][test_clusters] += 1\n",
    "            \n",
    "#             for each in test_clusters:\n",
    "#                 test_histogram[i][each] += 1\n",
    "        \n",
    "    test_histogram = scale.transform(test_histogram)\n",
    "    \n",
    "    score = clf.score(test_histogram,testing_label)\n",
    "    print(score*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[324. 318.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5c42991b3efb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m#Testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mpredicted_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecognize_test_videos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtesting_folders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkmeans_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-d2ac397bebef>\u001b[0m in \u001b[0;36mrecognize_test_videos\u001b[1;34m(testing_label, testing_folder, path, clf, scale, kmeans_obj)\u001b[0m\n\u001b[0;32m    124\u001b[0m                 \u001b[0mtest_histogram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meach\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[0mtest_histogram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_histogram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_histogram\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtesting_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, y, copy)\u001b[0m\n\u001b[0;32m    750\u001b[0m         X = check_array(X, accept_sparse='csr', copy=copy, warn_on_dtype=True,\n\u001b[0;32m    751\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 752\u001b[1;33m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[0;32m    753\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    550\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[324. 318.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "path = \"./Data/Frames/\"\n",
    "# training_folders, testing_folder, y_train, y_test = load_data(path)\n",
    "training_folders = np.load(\"training_folders.npy\")\n",
    "testing_folders = np.load(\"testing_folders.npy\")\n",
    "y_train = np.load(\"training_labels.npy\")\n",
    "y_test = np.load(\"testing_labels.npy\")\n",
    "    \n",
    "# find_features(path,training_folders)\n",
    "descriptor_list = np.load(\"./Data/training_descriptors.npy\")\n",
    "\n",
    "descriptor_stack = stack_vertically(descriptor_list)\n",
    "# descriptor_stack = np.load(\"./Data/descriptor_stack.npy\")\n",
    "\n",
    "\n",
    "#clustering\n",
    "clustered_objects,kmeans_obj = cluster(descriptor_stack)\n",
    "\n",
    "#creating visual vocabulary\n",
    "histogram = create_bovw_histogram(clustered_objects,training_folders,descriptor_list,path)\n",
    "\n",
    "#normalizing the histogram\n",
    "standardized_histogram, scale = normalize_histogram(histogram)\n",
    "\n",
    "# Training\n",
    "clf  = SVC()\n",
    "clf = train_bovw(standardized_histogram,y_train,clf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1290,20) (2,) (1290,20) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-c95f5d2abeff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredicted_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecognize_test_videos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtesting_folders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkmeans_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-66f2e3fa4364>\u001b[0m in \u001b[0;36mrecognize_test_videos\u001b[1;34m(testing_label, testing_folder, path, clf, scale, kmeans_obj)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;31m#                 test_histogram[i][each] += 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[0mtest_histogram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_histogram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_histogram\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtesting_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, y, copy)\u001b[0m\n\u001b[0;32m    761\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m                 \u001b[0mX\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1290,20) (2,) (1290,20) "
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "predicted_labels = recognize_test_videos(y_test,testing_folders,path,clf,scale,kmeans_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
